{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f90e5e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== STUDENT PERFORMANCE PREDICTION MODEL ====\n",
      "Loading data...\n",
      "\n",
      "==== DATASET OVERVIEW ====\n",
      "Shape: (1000, 8)\n",
      "\n",
      "Column data types:\n",
      "gender                         object\n",
      "race/ethnicity                 object\n",
      "parental level of education    object\n",
      "lunch                          object\n",
      "test preparation course        object\n",
      "math score                      int64\n",
      "reading score                   int64\n",
      "writing score                   int64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "No missing values\n",
      "\n",
      "Basic statistics for numerical features:\n",
      "       math score  reading score  writing score\n",
      "count  1000.00000    1000.000000    1000.000000\n",
      "mean     66.08900      69.169000      68.054000\n",
      "std      15.16308      14.600192      15.195657\n",
      "min       0.00000      17.000000      10.000000\n",
      "25%      57.00000      59.000000      57.750000\n",
      "50%      66.00000      70.000000      69.000000\n",
      "75%      77.00000      79.000000      79.000000\n",
      "max     100.00000     100.000000     100.000000\n",
      "\n",
      "Numeric features: 2\n",
      "Categorical features: 5\n",
      "\n",
      "==== CREATING VISUALIZATIONS ====\n",
      "Visualizations created and saved in 'visualizations' folder\n",
      "\n",
      "==== BUILDING AND TRAINING MODELS ====\n",
      "\n",
      "Training SGD Linear Regression...\n",
      "SGD Linear Regression - Train MSE: 27.67, Test MSE: 30.86\n",
      "SGD Linear Regression - Train MAE: 4.20, Test MAE: 4.41\n",
      "SGD Linear Regression - R² Score: 0.88\n",
      "\n",
      "Training Linear Regression...\n",
      "Linear Regression - Train MSE: 27.54, Test MSE: 30.89\n",
      "Linear Regression - Train MAE: 4.20, Test MAE: 4.42\n",
      "Linear Regression - R² Score: 0.88\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree - Train MSE: 0.09, Test MSE: 65.00\n",
      "Decision Tree - Train MAE: 0.02, Test MAE: 6.49\n",
      "Decision Tree - R² Score: 0.74\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest - Train MSE: 5.32, Test MSE: 37.67\n",
      "Random Forest - Train MAE: 1.84, Test MAE: 4.88\n",
      "Random Forest - R² Score: 0.85\n",
      "\n",
      "Best model based on test MSE: SGD Linear Regression\n",
      "\n",
      "==== SAVING BEST MODEL ====\n",
      "Best model saved as './models/best_student_performance_model.pkl'\n",
      "\n",
      "==== MODEL TRAINING COMPLETE ====\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "def analyze_and_preprocess(df, target_column='math score'):\n",
    "    \"\"\"\n",
    "    Analyze and preprocess the dataset\n",
    "    \"\"\"\n",
    "    print(\"\\n==== DATASET OVERVIEW ====\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"\\nColumn data types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\nMissing values:\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"No missing values\")\n",
    "    \n",
    "    # Basic statistics for numerical columns\n",
    "    print(\"\\nBasic statistics for numerical features:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    # Identify numerical and categorical columns\n",
    "    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    if target_column in numeric_features:\n",
    "        numeric_features.remove(target_column)\n",
    "    \n",
    "    categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    print(f\"\\nNumeric features: {len(numeric_features)}\")\n",
    "    print(f\"Categorical features: {len(categorical_features)}\")\n",
    "    \n",
    "    # Handle any missing values\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            if col in numeric_features:\n",
    "                df[col].fillna(df[col].median(), inplace=True)\n",
    "            else:\n",
    "                df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    \n",
    "    return df, numeric_features, categorical_features\n",
    "\n",
    "def create_visualizations(df, numeric_features, categorical_features, target_column):\n",
    "    \"\"\"\n",
    "    Create visualizations for data analysis\n",
    "    \"\"\"\n",
    "    print(\"\\n==== CREATING VISUALIZATIONS ====\")\n",
    "    os.makedirs('visualizations', exist_ok=True)\n",
    "    \n",
    "    # Correlation heatmap for numerical features\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    correlation_features = numeric_features.copy()\n",
    "    correlation_features.append(target_column)\n",
    "    \n",
    "    correlation_matrix = df[correlation_features].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title('Correlation Heatmap of Numeric Features')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/correlation_heatmap.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Distribution of the target variable\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[target_column], kde=True)\n",
    "    plt.title(f'Distribution of {target_column}')\n",
    "    plt.xlabel(target_column)\n",
    "    plt.savefig(f'visualizations/{target_column}_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Visualizing relationships between key numeric features and the target\n",
    "    if len(numeric_features) > 0:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i, feature in enumerate(numeric_features, 1):\n",
    "            plt.subplot(2, 2, i)\n",
    "            sns.scatterplot(x=feature, y=target_column, data=df)\n",
    "            plt.title(f'{feature} vs {target_column}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('visualizations/feature_relationships.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Boxplots for categorical features\n",
    "    if len(categorical_features) > 0:\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        for i, feature in enumerate(categorical_features, 1):\n",
    "            plt.subplot(3, 2, i)\n",
    "            sns.boxplot(x=feature, y=target_column, data=df)\n",
    "            plt.title(f'{target_column} by {feature}')\n",
    "            plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('visualizations/categorical_boxplots.png')\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"Visualizations created and saved in 'visualizations' folder\")\n",
    "\n",
    "def build_and_train_models(X, y, numeric_features, categorical_features):\n",
    "    \"\"\"\n",
    "    Build, train and evaluate models\n",
    "    \"\"\"\n",
    "    print(\"\\n==== BUILDING AND TRAINING MODELS ====\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Define preprocessing for numeric and categorical features\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Create models dictionary\n",
    "    models = {\n",
    "        'SGD Linear Regression': Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', SGDRegressor(max_iter=1000, tol=1e-3, random_state=42))\n",
    "        ]),\n",
    "        \n",
    "        'Linear Regression': Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', LinearRegression())\n",
    "        ]),\n",
    "        \n",
    "        'Decision Tree': Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "        ]),\n",
    "        \n",
    "        'Random Forest': Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'train_mse': train_mse,\n",
    "            'test_mse': test_mse,\n",
    "            'train_mae': train_mae,\n",
    "            'test_mae': test_mae,\n",
    "            'r2': r2\n",
    "        }\n",
    "        \n",
    "        print(f\"{name} - Train MSE: {train_mse:.2f}, Test MSE: {test_mse:.2f}\")\n",
    "        print(f\"{name} - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\n",
    "        print(f\"{name} - R² Score: {r2:.2f}\")\n",
    "    \n",
    "    # Plot model comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    models_list = list(results.keys())\n",
    "    test_mse_list = [results[model]['test_mse'] for model in models_list]\n",
    "    \n",
    "    plt.bar(models_list, test_mse_list)\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Test MSE')\n",
    "    plt.title('Model Comparison (Lower is Better)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/model_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Find the best model (lowest test MSE)\n",
    "    best_model_name = min(results, key=lambda k: results[k]['test_mse'])\n",
    "    print(f\"\\nBest model based on test MSE: {best_model_name}\")\n",
    "    \n",
    "    return models, results, best_model_name\n",
    "\n",
    "def save_best_model(best_model, numeric_features, categorical_features, target_column):\n",
    "    \"\"\"\n",
    "    Save the best model and create a prediction script\n",
    "    \"\"\"\n",
    "    print(\"\\n==== SAVING BEST MODEL ====\")\n",
    "    \n",
    "    # Create models directory if it doesn't exist\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    \n",
    "    # Save the model\n",
    "    model_file = './models/best_student_performance_model.pkl'\n",
    "    joblib.dump(best_model, model_file)\n",
    "    \n",
    "    # Save feature lists\n",
    "    feature_file = './models/model_features.pkl'\n",
    "    joblib.dump({\n",
    "        'numeric_features': numeric_features,\n",
    "        'categorical_features': categorical_features,\n",
    "        'target_column': target_column\n",
    "    }, feature_file)\n",
    "    \n",
    "    print(f\"Best model saved as '{model_file}'\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"==== STUDENT PERFORMANCE PREDICTION MODEL ====\")\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv('StudentsPerformance.csv')\n",
    "    \n",
    "    # Set target column\n",
    "    target_column = 'math score'\n",
    "    \n",
    "    # Analyze and preprocess data\n",
    "    df, numeric_features, categorical_features = analyze_and_preprocess(df, target_column)\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_visualizations(df, numeric_features, categorical_features, target_column)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Build and train models\n",
    "    models, results, best_model_name = build_and_train_models(X, y, numeric_features, categorical_features)\n",
    "    \n",
    "    # Save the best model\n",
    "    save_best_model(models[best_model_name], numeric_features, categorical_features, target_column)\n",
    "    \n",
    "    print(\"\\n==== MODEL TRAINING COMPLETE ====\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
